{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PIL as pil\n",
    "#import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import  xml.dom.minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 16:48:25.327334: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-08 16:48:25.435641: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-08 16:48:25.435851: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=\"/home/haziq/Documents/VIP-Project/Detection/VOC2007/JPEGImages/\"\n",
    "annotation_path=\"/home/haziq/Documents/VIP-Project/Detection/VOC2007/Annotations/\"\n",
    " \n",
    "files_name = os.listdir(image_path)\n",
    "for filename in files_name:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import  xml.dom.minidom\n",
    "# missing = IP048000152\n",
    "missing = [\"IP048000152.jpg\",\"IP053000086.jpg\"]\n",
    " \n",
    "image_path=\"/home/haziq/Documents/VIP-Project/Detection/VOC2007/JPEGImages/\"\n",
    "annotation_path=\"/home/haziq/Documents/VIP-Project/Detection/VOC2007/Annotations/\"\n",
    " \n",
    "files_name = os.listdir(image_path)\n",
    "for filename_ in files_name:\n",
    "    if filename_ not in missing:\n",
    "        print(filename)\n",
    "        filename, extension= os.path.splitext(filename_)\n",
    "        img_path =image_path+filename+'.jpg'\n",
    "        xml_path =annotation_path+filename+'.xml'\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "        \tpass\n",
    "        dom = xml.dom.minidom.parse(xml_path)\n",
    "        root = dom.documentElement\n",
    "        objects=dom.getElementsByTagName(\"object\")\n",
    "        print(objects)\n",
    "        i=0\n",
    "        for object in objects:\n",
    "            bndbox = root.getElementsByTagName('bndbox')[i]\n",
    "            xmin = bndbox.getElementsByTagName('xmin')[0]\n",
    "            ymin = bndbox.getElementsByTagName('ymin')[0]\n",
    "            xmax = bndbox.getElementsByTagName('xmax')[0]\n",
    "            ymax = bndbox.getElementsByTagName('ymax')[0]\n",
    "            xmin_data=xmin.childNodes[0].data\n",
    "            ymin_data=ymin.childNodes[0].data\n",
    "            xmax_data=xmax.childNodes[0].data\n",
    "            ymax_data=ymax.childNodes[0].data\n",
    "            print(object)        \n",
    "            print(xmin_data)\n",
    "            print(ymin_data)    \n",
    "            i= i +1 \n",
    "            cv2.rectangle(img,(int(xmin_data),int(ymin_data)),(int(xmax_data),int(ymax_data)),(55,255,155),5)\n",
    "        flag=0\n",
    "        flag=cv2.imwrite(\"/home/haziq/Documents/VIP-Project/Detection/VOC2007/Flags/{}.jpg\".format(filename),img)\n",
    "        if(flag):\n",
    "        \tprint(filename,\"done\")\n",
    "print(\"all done ====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping Cython as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCloning into 'models'...\n",
      "remote: Enumerating objects: 4067, done.\u001b[K\n",
      "remote: Counting objects: 100% (4067/4067), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3039/3039), done.\u001b[K\n",
      "remote: Total 4067 (delta 1179), reused 2939 (delta 968), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (4067/4067), 44.57 MiB | 16.19 MiB/s, done.\n",
      "Resolving deltas: 100% (1179/1179), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the tensorflow models repository from GitHub\n",
    "!pip uninstall Cython -y # Temporary fix for \"No module named 'object_detection'\" error\n",
    "!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify setup.py file to install the tf-models-official repository targeted at TF v2.8.0\n",
    "import re\n",
    "with open('models/research/object_detection/packages/tf2/setup.py') as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open('models/research/setup.py', 'w') as f:\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('tf-models-official>=2.5.1',\n",
    "               'tf-models-official==2.8.0', s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.3\n",
      "  Using cached PyYAML-5.3-cp311-cp311-linux_x86_64.whl\n",
      "Installing collected packages: pyyaml\n",
      "Successfully installed pyyaml-5.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Processing ./models/research\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting avro-python3 (from object_detection==0.1)\n",
      "  Using cached avro-python3-1.10.2.tar.gz (38 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting apache-beam (from object_detection==0.1)\n",
      "  Obtaining dependency information for apache-beam from https://files.pythonhosted.org/packages/eb/0a/5265daf46e686570423cc1b923e2e124e2b5661e1ffa420ca949751ab871/apache_beam-2.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached apache_beam-2.53.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pillow in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from object_detection==0.1) (10.2.0)\n",
      "Collecting lxml (from object_detection==0.1)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/1f/09/df0101e6d7be06fca545c0f7417d03d69679ff280d892a406469086780a4/lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached lxml-5.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: matplotlib in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from object_detection==0.1) (3.8.2)\n",
      "Collecting Cython (from object_detection==0.1)\n",
      "  Obtaining dependency information for Cython from https://files.pythonhosted.org/packages/26/2c/6a887c957aa53e44f928119dea628a5dfacc8e875424034f5fecac9daba4/Cython-3.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached Cython-3.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting contextlib2 (from object_detection==0.1)\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tf-slim (from object_detection==0.1)\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: six in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from object_detection==0.1) (1.16.0)\n",
      "Collecting pycocotools (from object_detection==0.1)\n",
      "  Obtaining dependency information for pycocotools from https://files.pythonhosted.org/packages/6c/07/3c94d317ea5a35adbfe25e04a2754cfcb7ccd8ffa3a2796ab873f0bc4b7a/pycocotools-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached pycocotools-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting lvis (from object_detection==0.1)\n",
      "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from object_detection==0.1) (1.12.0)\n",
      "Requirement already satisfied: pandas in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from object_detection==0.1) (2.2.0)\n",
      "Collecting tf-models-official==2.8.0 (from object_detection==0.1)\n",
      "  Using cached tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
      "Collecting tensorflow-io (from object_detection==0.1)\n",
      "  Obtaining dependency information for tensorflow-io from https://files.pythonhosted.org/packages/a5/0e/a0cf8e7d67d60da20d437bc204c8a8b98f2a8455c2ae75ea2f1809c6a66f/tensorflow_io-0.36.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tensorflow_io-0.36.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting keras (from object_detection==0.1)\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/a3/31/982a0c8da5e06b8e915e09e7cae7f7815eecfef7e9e16fd733b105aa09ab/keras-3.0.4-py3-none-any.whl.metadata\n",
      "  Using cached keras-3.0.4-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
      "  Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "Collecting gin-config (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting google-api-python-client>=1.6.7 (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Obtaining dependency information for google-api-python-client>=1.6.7 from https://files.pythonhosted.org/packages/73/e4/d8d38ca79045a72880c98e6d2ebc737c92d596d5dc0bf2e4233b00be5daa/google_api_python_client-2.116.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_api_python_client-2.116.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Using cached kaggle-1.6.5.tar.gz (84 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from tf-models-official==2.8.0->object_detection==0.1) (1.26.4)\n",
      "Collecting oauth2client (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting opencv-python-headless (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Obtaining dependency information for opencv-python-headless from https://files.pythonhosted.org/packages/71/19/3c65483a80a1d062d46ae20faf5404712d25cb1dfdcaf371efbd67c38544/opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.9.8)\n",
      "Collecting py-cpuinfo>=3.3.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /home/haziq/Documents/VIP-Project/detection/lib/python3.11/site-packages (from tf-models-official==2.8.0->object_detection==0.1) (5.3)\n",
      "Collecting sentencepiece (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting seqeval (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-addons (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Obtaining dependency information for tensorflow-addons from https://files.pythonhosted.org/packages/24/94/80165946ec4986505cbfac29b5ae79544bfe2200d9d7883e1ad7c7342a55/tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-datasets (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Obtaining dependency information for tensorflow-datasets from https://files.pythonhosted.org/packages/fe/18/4865973f5469cfe33bbe1cfc2f1918335eb44f4cc3d316c1bce22c1af2bc/tensorflow_datasets-4.9.4-py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_datasets-4.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting tensorflow-hub>=0.6.0 (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Obtaining dependency information for tensorflow-hub>=0.6.0 from https://files.pythonhosted.org/packages/e5/50/00dba77925bf2a0a1e45d7bcf8a69a1d2534fb4bb277d9010bd148d2235e/tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.8.0->object_detection==0.1)\n",
      "  Obtaining dependency information for tensorflow-model-optimization>=0.4.1 from https://files.pythonhosted.org/packages/5a/a0/f38c9ce977285d3f347f6d64cf227924fe9fc97d780d6df4a55563e311af/tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.28.0 Requires-Python >=3.7, <3.11; 2.10.0 Requires-Python >=2.7,<3.0; 2.3.0 Requires-Python >=2.7,<3.0; 2.4.0 Requires-Python >=2.7,<3.0; 2.5.0 Requires-Python >=2.7,<3.0; 2.6.0 Requires-Python >=2.7,<3.0; 2.7.0 Requires-Python >=2.7,<3.0; 2.8.0 Requires-Python >=2.7,<3.0; 2.9.0 Requires-Python >=2.7,<3.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-text~=2.8.0 (from tf-models-official) (from versions: 2.12.0rc0, 2.12.0, 2.12.1, 2.13.0rc0, 2.14.0rc0, 2.14.0, 2.15.0rc0, 2.15.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-text~=2.8.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml==5.3\n",
    "!pip install models/research/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/haziq/Documents/VIP-Project/Detection/VOC2007/models/research/object_detection/builders/model_builder_tf2_test.py\", line 20, in <module>\n",
      "    from absl.testing import parameterized\n",
      "ModuleNotFoundError: No module named 'absl'\n"
     ]
    }
   ],
   "source": [
    "# Run Model Bulider Test file, just to verify everything's working properly\n",
    "!python models/research/object_detection/builders/model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
